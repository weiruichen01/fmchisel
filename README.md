<!-- PROJECT TITLE & BADGES -->
<h1 align="center">FMCHISEL â€“ Efficient Foundation Model Algorithms</h1>

<p align="center">
  <b>State-of-the-art compression & distillation recipes for Large Language Models</b><br/>
</p>

---

## âœ¨ Overview

FMCHISEL (_Foundation&nbsp;Model&nbsp;Chisel_) is an **open-source research library** that makes it simple to:

* **Compress** LLMs with cutting-edge pruning and quantization techniques.
* **Distill** knowledge from larger models to smaller ones.
* **Accelerate** inference on consumer hardware by combining sparse + low-bit weight formats.
* **Train** efficiently with advanced optimizers such as schedule-free **AdamW**.
* **Prototype** new compression ideas rapidly.

FMCHISEL is built on **PyTorch** and integrates seamlessly with ðŸ“š **ðŸ¤— Transformers**.

---

## ðŸ“¦ Installation

The package will soon be available on PyPI. Until then, install from source (note that a Linux system will be required):

```bash
# Clone the repo
git clone https://github.com/linkedin/FMCHISEL.git
cd fmchisel

# Install with all optional dependencies
pip install -e ".[all]"
```

---

## ðŸš€ Quick Start

Start with these ready-to-run recipes from the `examples/` folder:

* **Distillation:** `examples/distillation/run.sh` â€“ distill a 8B teacher into a 1B student model
* **Unstructured Pruning:** `examples/pruning/run.sh` â€“ N:M semi-structured pruning in one shot  
* **Structured Pruning:** `examples/structured_pruning/run.sh` â€“ remove entire heads / neurons  

Simply run a script (or tweak hyper-parameters) and youâ€™re good to go!

---

## ðŸ—‚ï¸ Project Structure

```
fmchisel/
â”‚
â”œâ”€ data/               # Calibration & data utilities
â”œâ”€ distillation/       # Knowledge-distillation components
â”œâ”€ pruning/            # ALPS, OSSCAR, SparseGPT, structured pruning
â”œâ”€ quantization/       # QuantEase & helpers
â”œâ”€ optimizers/         # AdamW schedule-free implementation
â”œâ”€ utils/              # Callbacks, training helpers
â””â”€ config.py           # Global configuration
examples/              # End-to-end reproducible recipes
tests/                 # PyTest suite
```

---

## ðŸ§ª Research Components

| Area            | Algorithm(s) | Implementation |
|-----------------|-------------------|----------------|
| **Pruning**     | ALPS | `fmchisel.pruning.alps` |
|                 | OSSCAR | `fmchisel.pruning.osscar` |
| **Quantization**| QuantEase | `fmchisel.quantization.quantease` |
| **Distillation**| Lightweight KD recipes | `fmchisel.distillation` |
| **Optimization**| AdamW Schedule-Free | `fmchisel.optimizers.adamw_schedulefree` |

---

## ðŸ› ï¸ Contributing

1. Fork & clone the repository.  
2. Install dev deps: `pip install -e ".[dev]"`  (note: A Linux system is required.)
3. Run linters/formatters: `make checkstyle`.  
4. Execute tests: `make test`.  
5. Open a pull request!

> [!NOTE]
> Please open an issue first to discuss major changes.

---

## ðŸ”’ License

See [LICENSE](LICENSE) for details.
